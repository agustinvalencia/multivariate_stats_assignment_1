\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Assignment 1 - Examining multivariate data},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Assignment 1 - Examining multivariate data}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{\textbf{GROUP 03}\\
Agustin Valencia - aguva779\\
Bayu Brahmantio - baybr878\\
Joris van Doorn - jorva845\\
Marcos F Mourao - marfr825}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{22 November 2019}


\begin{document}
\maketitle

\hypertarget{question-1-describing-individual-variables}{%
\section{Question 1: Describing individual
variables}\label{question-1-describing-individual-variables}}

\hypertarget{a-describe-the-7-variables-with-mean-values-standard-deviations-e.t.c.}{%
\subsection{a) Describe the 7 variables with mean values, standard
deviations
e.t.c.}\label{a-describe-the-7-variables-with-mean-values-standard-deviations-e.t.c.}}

\begin{verbatim}
## ** Summarizing data **
\end{verbatim}

\begin{verbatim}
## 
## 
## *data path:  data/T1-9.dat
\end{verbatim}

\begin{verbatim}
## 
## 
## *Column means:
\end{verbatim}

\begin{verbatim}
##       100m       200m       400m       800m      1500m      3000m 
##  11.357778  23.118519  51.989074   2.022407   4.189444   9.080741 
##   marathon 
## 153.619259
\end{verbatim}

\begin{verbatim}
## 
## *Variances:
\end{verbatim}

\begin{verbatim}
## [1] 1.553157e-01 8.630883e-01 6.745458e+00 7.546925e-03 7.418270e-02
## [6] 6.647579e-01 2.702702e+02
\end{verbatim}

\begin{verbatim}
## 
## *Total Sample Variance:
\end{verbatim}

\begin{verbatim}
## [1] 278.7805
\end{verbatim}

\begin{verbatim}
## 
## *Generalized Sample Variance:
\end{verbatim}

\begin{verbatim}
## [1] 8.195897e-07
\end{verbatim}

\hypertarget{b-illustrate-the-variables-with-different-graphs-explore-what-plotting-possibilities-r-has.-make-sure-that-the-graphs-look-attractive-it-is-absolutely-necessary-to-look-at-the-labels-font-sizes-point-types.-are-there-any-apparent-extreme-values-do-the-variables-seem-normally-distributed-plot-the-best-fitting-match-the-mean-and-standard-deviation-i.e.-method-of-moments-gaussian-density-curve-on-the-datas-histogram.-for-the-last-part-you-may-be-interested-in-the-hist-and-density-functions.}{%
\subsection{b) Illustrate the variables with different graphs (explore
what plotting possibilities R has). Make sure that the graphs look
attractive (it is absolutely necessary to look at the labels, font
sizes, point types). Are there any apparent extreme values? Do the
variables seem normally distributed? Plot the best fitting (match the
mean and standard deviation, i.e.~method of moments) Gaussian density
curve on the data's histogram. For the last part you may be interested
in the hist() and density()
functions.}\label{b-illustrate-the-variables-with-different-graphs-explore-what-plotting-possibilities-r-has.-make-sure-that-the-graphs-look-attractive-it-is-absolutely-necessary-to-look-at-the-labels-font-sizes-point-types.-are-there-any-apparent-extreme-values-do-the-variables-seem-normally-distributed-plot-the-best-fitting-match-the-mean-and-standard-deviation-i.e.-method-of-moments-gaussian-density-curve-on-the-datas-histogram.-for-the-last-part-you-may-be-interested-in-the-hist-and-density-functions.}}

\begin{verbatim}
## Using country as id variables
\end{verbatim}

\begin{center}\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-3-1} \end{center}

\begin{center}\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-5-1} \end{center}

\begin{center}\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-5-2} \end{center}

\begin{center}\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-5-3} \end{center}

\begin{center}\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-5-4} \end{center}

\begin{center}\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-5-5} \end{center}

\begin{center}\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-5-6} \end{center}

\begin{center}\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-5-7} \end{center}

The first categories (100m, 200m and 400m) seem normally distributed by
looking at the histograms. The longer races are have more skewed to the
right histograms.

\hypertarget{question-2-relationships-between-the-variables}{%
\section{Question 2: Relationships between the
variables}\label{question-2-relationships-between-the-variables}}

\hypertarget{a-compute-the-covariance-and-correlation-matrices-for-the-7-variables.-is-there-any-apparent-structure-in-them-save-these-matrices-for-future-use.}{%
\subsection{a) Compute the covariance and correlation matrices for the 7
variables. Is there any apparent structure in them? Save these matrices
for future
use.}\label{a-compute-the-covariance-and-correlation-matrices-for-the-7-variables.-is-there-any-apparent-structure-in-them-save-these-matrices-for-future-use.}}

Covariance Matrix:

\begin{longtable}[]{@{}lrrrrrrr@{}}
\toprule
& 100m & 200m & 400m & 800m & 1500m & 3000m & marathon\tabularnewline
\midrule
\endhead
100m & 0.1553157 & 0.3445608 & 0.8912960 & 0.0277036 & 0.0838912 &
0.2338828 & 4.334178\tabularnewline
200m & 0.3445608 & 0.8630883 & 2.1928363 & 0.0661659 & 0.2027633 &
0.5543502 & 10.384988\tabularnewline
400m & 0.8912960 & 2.1928363 & 6.7454576 & 0.1818079 & 0.5091768 &
1.4268158 & 28.903731\tabularnewline
800m & 0.0277036 & 0.0661659 & 0.1818079 & 0.0075469 & 0.0214146 &
0.0613793 & 1.219655\tabularnewline
1500m & 0.0838912 & 0.2027633 & 0.5091768 & 0.0214146 & 0.0741827 &
0.2161551 & 3.539837\tabularnewline
3000m & 0.2338828 & 0.5543502 & 1.4268158 & 0.0613793 & 0.2161551 &
0.6647579 & 10.706091\tabularnewline
marathon & 4.3341776 & 10.3849876 & 28.9037314 & 1.2196546 & 3.5398373 &
10.7060911 & 270.270150\tabularnewline
\bottomrule
\end{longtable}

Correlation Matrix:

\begin{longtable}[]{@{}lrrrrrrr@{}}
\toprule
& 100m & 200m & 400m & 800m & 1500m & 3000m & marathon\tabularnewline
\midrule
\endhead
100m & 1.0000000 & 0.9410886 & 0.8707802 & 0.8091758 & 0.7815510 &
0.7278784 & 0.6689597\tabularnewline
200m & 0.9410886 & 1.0000000 & 0.9088096 & 0.8198258 & 0.8013282 &
0.7318546 & 0.6799537\tabularnewline
400m & 0.8707802 & 0.9088096 & 1.0000000 & 0.8057904 & 0.7197996 &
0.6737991 & 0.6769384\tabularnewline
800m & 0.8091758 & 0.8198258 & 0.8057904 & 1.0000000 & 0.9050509 &
0.8665732 & 0.8539900\tabularnewline
1500m & 0.7815510 & 0.8013282 & 0.7197996 & 0.9050509 & 1.0000000 &
0.9733801 & 0.7905565\tabularnewline
3000m & 0.7278784 & 0.7318546 & 0.6737991 & 0.8665732 & 0.9733801 &
1.0000000 & 0.7987302\tabularnewline
marathon & 0.6689597 & 0.6799537 & 0.6769384 & 0.8539900 & 0.7905565 &
0.7987302 & 1.0000000\tabularnewline
\bottomrule
\end{longtable}

By analysing the variance covariance matrix, it can be concluded that
countries that have a high performance in ``shorter'' races (100m, 200m
and 400m) do not necessarily have high performance in ``long distance''
races (800m, 1500m, 3000m and marathon). This is coherent to the fact
that short and long races require different training. Normally, the
athletes are different altogether in these different categories.

\hypertarget{b-generate-and-study-the-scatterplots-between-each-pair-of-variables.-any-extreme-values}{%
\subsection{\texorpdfstring{b) Generate and study the scatterplots
between each pair of variables. Any extreme values?
\textcolor{red}{STILL NEED TO ANSWER THIS QUESTION}}{b) Generate and study the scatterplots between each pair of variables. Any extreme values? }}\label{b-generate-and-study-the-scatterplots-between-each-pair-of-variables.-any-extreme-values}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{scatterplotMatrix}\NormalTok{(data[,}\DecValTok{2}\OperatorTok{:}\DecValTok{8}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-8-1.pdf}

\hypertarget{c-explore-what-other-plotting-possibilities-r-offers-for-multivariate-data.-present-other-at-least-two-graphs-that-you-find-interesting-with-respect-to-this-data-set.}{%
\subsection{c) Explore what other plotting possibilities R offers for
multivariate data. Present other (at least two) graphs that you find
interesting with respect to this data
set.}\label{c-explore-what-other-plotting-possibilities-r-offers-for-multivariate-data.-present-other-at-least-two-graphs-that-you-find-interesting-with-respect-to-this-data-set.}}

\textcolor{red}{STILL NEED TO ANSWER THIS QUESTION}

\hypertarget{question-3-examining-for-extreme-values}{%
\section{Question 3: Examining for extreme
values}\label{question-3-examining-for-extreme-values}}

\hypertarget{a-look-at-the-plots-esp.-scatterplots-generated-in-the-previous-question.-which-34-countries-appear-most-extreme-why-do-you-consider-them-extreme}{%
\subsection{a) Look at the plots (esp.~scatterplots) generated in the
previous question. Which 3--4 countries appear most extreme? Why do you
consider them
extreme?}\label{a-look-at-the-plots-esp.-scatterplots-generated-in-the-previous-question.-which-34-countries-appear-most-extreme-why-do-you-consider-them-extreme}}

\textcolor{red}{STILL NEED TO ANSWER THIS QUESTION}

\hypertarget{b-the-most-common-residual-is-the-euclidean-distance-between-the-observation-and-sample-mean-vector-i.e.}{%
\subsection{b) The most common residual is the Euclidean distance
between the observation and sample mean vector,
i.e.}\label{b-the-most-common-residual-is-the-euclidean-distance-between-the-observation-and-sample-mean-vector-i.e.}}

\[d(\overrightarrow{x},\overline{x}) = \sqrt{(\overrightarrow{x} - \overline{x})^T (\overrightarrow{x} - \overline{x})}\]

\hypertarget{this-distance-can-be-immediately-generalized-to-the-lr-r-0-distance-as}{%
\subsection{\texorpdfstring{This distance can be immediately generalized
to the \(L^r\), r \textgreater{} 0 distance
as}{This distance can be immediately generalized to the L\^{}r, r \textgreater{} 0 distance as}}\label{this-distance-can-be-immediately-generalized-to-the-lr-r-0-distance-as}}

\[d_{L^r}(\overrightarrow{x} , \overline{x}) = \left( \sum_{i=1}^{p}{\lvert\overrightarrow{x}_i - \overline{x}_i\rvert^r} \right) ^ {1/r}\]

\hypertarget{where-p-is-the-dimension-of-the-observation-here-p-7.}{%
\subsection{where p is the dimension of the observation (here p =
7).}\label{where-p-is-the-dimension-of-the-observation-here-p-7.}}

\hypertarget{compute-the-squared-euclidean-distance-i.e.-r-2-of-the-observation-from-the-sample-mean-for-all-55-countries-using-rs-matrix-operations.-first-center-the-raw-data-by-the-means-to-get-x---mean-for-each-country.-then-do-a-calculation-with-matrices-that-will-result-in-a-matrix-that-has-on-its-diagonal-the-requested-squared-distance-for-each-country.-copy-this-diagonal-to-a-vector-and-report-on-the-five-most-extreme-countries.-in-this-questions-you-may-not-use-any-loops.}{%
\subsection{Compute the squared Euclidean distance (i.e.~r = 2) of the
observation from the sample mean for all 55 countries using R's matrix
operations. First center the raw data by the means to get x - mean for
each country. Then do a calculation with matrices that will result in a
matrix that has on its diagonal the requested squared distance for each
country. Copy this diagonal to a vector and report on the five most
extreme countries. In this questions you MAY NOT use any
loops.}\label{compute-the-squared-euclidean-distance-i.e.-r-2-of-the-observation-from-the-sample-mean-for-all-55-countries-using-rs-matrix-operations.-first-center-the-raw-data-by-the-means-to-get-x---mean-for-each-country.-then-do-a-calculation-with-matrices-that-will-result-in-a-matrix-that-has-on-its-diagonal-the-requested-squared-distance-for-each-country.-copy-this-diagonal-to-a-vector-and-report-on-the-five-most-extreme-countries.-in-this-questions-you-may-not-use-any-loops.}}

\begin{verbatim}
## Warning in sqrt((centered) %*% t(centered)): NaNs produced
\end{verbatim}

\begin{verbatim}
## [1] "Top 5 distance extreme countries:"
\end{verbatim}

\begin{verbatim}
## [1] PNG COK SAM BER GBR
## 54 Levels: ARG AUS AUT BEL BER BRA CAN CHI CHN COK COL CRC CZE DEN ... USA
\end{verbatim}

\begin{verbatim}
## [1] "Sweden's distance rank:  48"
\end{verbatim}

\hypertarget{c-the-different-variables-have-different-scales-so-it-is-possible-that-the-distances-can-be-dominated-by-some-few-variables.-to-avoid-this-we-can-use-the-squared-distance-where-v-is-a-diagonal-matrix-with-variances-of-the-appropriate-variables-on-the-diagonal.-the-effect-is-that-for-each-variable-the-squared-distance-is-divided-by-its-variance-and-we-have-a-scaled-independent-distance.}{%
\subsection{\texorpdfstring{c) The different variables have different
scales so it is possible that the distances can be dominated by some few
variables. To avoid this we can use the squared distance,
\textcolor{red}{**INSERT LATEX FORMULA HERE**} where V is a diagonal
matrix with variances of the appropriate variables on the diagonal. The
effect, is that for each variable the squared distance is divided by its
variance and we have a scaled independent
distance.}{c) The different variables have different scales so it is possible that the distances can be dominated by some few variables. To avoid this we can use the squared distance,  where V is a diagonal matrix with variances of the appropriate variables on the diagonal. The effect, is that for each variable the squared distance is divided by its variance and we have a scaled independent distance.}}\label{c-the-different-variables-have-different-scales-so-it-is-possible-that-the-distances-can-be-dominated-by-some-few-variables.-to-avoid-this-we-can-use-the-squared-distance-where-v-is-a-diagonal-matrix-with-variances-of-the-appropriate-variables-on-the-diagonal.-the-effect-is-that-for-each-variable-the-squared-distance-is-divided-by-its-variance-and-we-have-a-scaled-independent-distance.}}

\hypertarget{it-is-simple-to-compute-this-measure-by-standardizing-the-raw-data-with-both-means-centering-and-standard-deviations-scaling-and-then-compute-the-euclidean-distance-for-the-normalized-data.-carry-out-these-computations-and-conclude-which-countries-are-the-most-extreme-ones.-how-do-your-conclusions-compare-with-the-unnormalized-ones}{%
\subsection{It is simple to compute this measure by standardizing the
raw data with both means (centering) and standard deviations (scaling),
and then compute the Euclidean distance for the normalized data. Carry
out these computations and conclude which countries are the most extreme
ones. How do your conclusions compare with the unnormalized
ones?}\label{it-is-simple-to-compute-this-measure-by-standardizing-the-raw-data-with-both-means-centering-and-standard-deviations-scaling-and-then-compute-the-euclidean-distance-for-the-normalized-data.-carry-out-these-computations-and-conclude-which-countries-are-the-most-extreme-ones.-how-do-your-conclusions-compare-with-the-unnormalized-ones}}

\begin{verbatim}
## [1] "Top 5 distance extreme countries:"
\end{verbatim}

\begin{verbatim}
## [1] SAM COK PNG USA SIN
## 54 Levels: ARG AUS AUT BEL BER BRA CAN CHI CHN COK COL CRC CZE DEN ... USA
\end{verbatim}

\begin{verbatim}
## [1] "Sweden's distance rank:  50"
\end{verbatim}

The euclidean distance for normalized data results in a different
country list for most extreme ones, altough some countries are in both
lists, but not necessarily in the same positions: Samoa (SAM), Cook
Islands (COK) and Papua-New Guinea (PNG). This second set of extremes is
more consistent because the for the first three race categories (100m,
200m and 400m), time is measured in seconds while the others (800m,
1500m, 3000m and marathon) are measured in minutes.

\hypertarget{d-the-most-common-statistical-distance-is-the-mahalanobis-distance-where-c-is-the-sample-covariance-matrix-calculated-from-the-data.-with-this-measure-we-also-use-the-relationships-covariances-between-the-variables-and-not-only-the-marginal-variances-as-dv-does.-compute-the-mahalanobis-distance-which-countries-are-most-extreme-now}{%
\subsection{\texorpdfstring{d) The most common statistical distance is
the Mahalanobis distance, \textcolor{red}{**INSERT LATEX FORMULA HERE**}
where C is the sample covariance matrix calculated from the data. With
this measure we also use the relationships (covariances) between the
variables (and not only the marginal variances as dV(·, ·) does).
Compute the Mahalanobis distance, which countries are most extreme
now?}{d) The most common statistical distance is the Mahalanobis distance,  where C is the sample covariance matrix calculated from the data. With this measure we also use the relationships (covariances) between the variables (and not only the marginal variances as dV(·, ·) does). Compute the Mahalanobis distance, which countries are most extreme now?}}\label{d-the-most-common-statistical-distance-is-the-mahalanobis-distance-where-c-is-the-sample-covariance-matrix-calculated-from-the-data.-with-this-measure-we-also-use-the-relationships-covariances-between-the-variables-and-not-only-the-marginal-variances-as-dv-does.-compute-the-mahalanobis-distance-which-countries-are-most-extreme-now}}

\begin{verbatim}
## [1] "Top 5 distance extreme countries:"
\end{verbatim}

\begin{verbatim}
## [1] SAM  PNG  KORN COK  MEX 
## 54 Levels: ARG AUS AUT BEL BER BRA CAN CHI CHN COK COL CRC CZE DEN ... USA
\end{verbatim}

\begin{verbatim}
## [1] "Sweden's distance rank:  54"
\end{verbatim}

The most extreme countries given by the Mahalanobis distance are: Samoa
(SAM), Papua New Guinea (PNG), North Korea (KORN), Cook Islands (COK)
and Mexico (MEX).

\hypertarget{e-compare-the-results-in-bd.-some-of-the-countries-are-in-the-upper-end-with-all-the-measures-and-perhaps-they-can-be-classified-as-extreme.-discuss-this.-but-also-notice-the-different-measures-give-rather-different-results-how-does-sweden-behave.-summarize-this-graphically.-produce-czekanowskis-diagram-using-e.g.-the-rmaczek-package.-in-case-of-problems-please-describe-them.}{%
\subsection{\texorpdfstring{e) Compare the results in b)--d). Some of
the countries are in the upper end with all the measures and perhaps
they can be classified as extreme. Discuss this. But also notice the
different measures give rather different results (how does Sweden
behave?). Summarize this graphically. Produce Czekanowski's diagram
using e.g.~the \texttt{RMaCzek} package. In case of problems please
describe
them.}{e) Compare the results in b)--d). Some of the countries are in the upper end with all the measures and perhaps they can be classified as extreme. Discuss this. But also notice the different measures give rather different results (how does Sweden behave?). Summarize this graphically. Produce Czekanowski's diagram using e.g.~the RMaCzek package. In case of problems please describe them.}}\label{e-compare-the-results-in-bd.-some-of-the-countries-are-in-the-upper-end-with-all-the-measures-and-perhaps-they-can-be-classified-as-extreme.-discuss-this.-but-also-notice-the-different-measures-give-rather-different-results-how-does-sweden-behave.-summarize-this-graphically.-produce-czekanowskis-diagram-using-e.g.-the-rmaczek-package.-in-case-of-problems-please-describe-them.}}

In this case, extreme countries normally have poor performance in races,
but that is not always the case. For some distances definitions, high
performance countries like USA and Great Britain appear as extremes as
well. So ``extremism'' is not a measure of how ``slow'' a country is,
but rather how far from the overall mean the country is. Graphically,
this means that the region of equal euclidean distance (a hypersphere)
gets distorted to regions of equal statistical distance
(hyperellipsoids) with different statistical weights applied: the
marginal variances in c) and variance-covariances in d).

By ranking the countries in decreasing order of distance, Sweden's
lowers in position in the rank for the different distances definitions
in questions b), c), and d) respectively (48th, 50th and 54th place). It
is possible to conclude that Sweden's records are more consistent
throught all race categories, since it is positioned in the bottom
positions of all ranks.

\textcolor{red}{I AM NOT SURE ABOUT THIS, PLEASE SOMEONE CHECK THESE ELLIPSES. IDK HOW TO PICK SHAPE AND RADIUS PARAMETERS.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(car)}
\CommentTok{#for 100m race}
\NormalTok{center <-}\StringTok{ }\KeywordTok{colMeans}\NormalTok{(records[,}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{])}
\NormalTok{shape1 <-}\StringTok{ }\KeywordTok{cov}\NormalTok{(records[,}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{])}
\NormalTok{shape2 <-}\StringTok{ }\NormalTok{V[}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{,}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{]}
\KeywordTok{plot}\NormalTok{(records[,}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{])}
\KeywordTok{ellipse}\NormalTok{(}\DataTypeTok{center =}\NormalTok{ center, }\DataTypeTok{shape =}\NormalTok{ shape1, }\DataTypeTok{radius =} \DecValTok{1}\NormalTok{)}
\KeywordTok{ellipse}\NormalTok{(}\DataTypeTok{center =}\NormalTok{ center, }\DataTypeTok{shape =}\NormalTok{ shape2, }\DataTypeTok{radius =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-12-1.pdf}

The Czekanowski's diagram is showed below:

\begin{center}\includegraphics{assingment_1_files/figure-latex/unnamed-chunk-13-1} \end{center}


\end{document}
